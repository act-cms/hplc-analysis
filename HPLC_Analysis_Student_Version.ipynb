{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# High-Performance Liquid Chromatography Analysis (Piloted Spring 2025) (Student Version)\n",
        "\n",
        "**Prior Knowledge Needed**\n",
        "*  Familiarity with *arrays*\n",
        "*  Familiarity with *functions*\n",
        "*  Familiarity with data sets that can be fit to a *model*, such as a linear calibration curve\n",
        "\n",
        "**Content Learning Objectives**\n",
        "*  Explain how using *high-performance liquid chromatography* (HPLC) permits separation of a mixture into more than one analyte, using *retention times* to identify well-separated peaks for each analyte.\n",
        "*  Explain how *spiked* samples permit verification of each analyte's identity and estimation of each analyte's concentration.\n",
        "*  Explain how *calibration curves* permit quantitative analysis of each analyte.\n",
        "\n",
        "**Process Learning Objectives**\n",
        "*  Use Python code to transform data using structures such as arrays\n",
        "*  Use Python code to visualize data using different types of graphs\n",
        "*  Use Python code to transform data using functions\n",
        "\n",
        "This Jupyter notebook can be used to generate code in Python to perform four data analysis tasks commonly used in HPLC data analysis:\n",
        "1. Input *stock* concentrations, and input all dilution volumes, measured peak areas, and measured retention times into arrays; and create arrays of diluted stock analyte concentrations\n",
        "2. Find the best-fit parameters and standard uncertainties to relate each analyte's peak area to its concentration; and generate calibration curves using data arrays and best-fit model arrays\n",
        "3. Use measured retention times and peak areas of spiked samples to identify analyte peaks in a chromatogram of a mixture, and to estimate each analyte's concentration in the mixture\n",
        "4. Calculate each unknown analyte's concentration and standard uncertainty; use these concentrations to calculate total amounts per tablet in mg.\n",
        "\n"
      ],
      "metadata": {
        "id": "HSQVFPBJMaAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: Entering Stock Concentrations, Volumes, Peak Areas, and Retention Times, and Calculating Diluted Analyte Concentrations\n",
        "\n",
        "In this task, you will need to enter data from your laboratory notebook into the empty variables and arrays in the sample-code.  Python code will then be used to calculate diluted analyte calculations using the dilution formula.\n",
        "\n",
        "Using the information above:\n",
        "\n",
        "1a) Double-click here in this **text cell** and type into each of the comment lines to **explain the purpose** of each line of sample-code below in this text cell(they should look like the example shown here).\n",
        "\n",
        "---\n",
        "```\n",
        "#### The code below is for:\n",
        "```\n",
        "---\n",
        "\n",
        "1b) **Enter the data** from your lab notebook into the appropriate arrays in the sample-code.  For each set of standard vials, please enter the peak areas in order of increasing concentration.  For each chromatogram with more than one peak, please enter the retention times and peak areas into the corresponding array in order of increasing retention time.  For replicate sample vials, please enter the replicate vials into arrays in the same order (*e.g.* Sample 1, Sample 2, Sample 3).\n",
        "\n",
        "1c) Copy/paste all the code along with your explanations into the **code cell** just below this text cell, and run it.\n",
        "\n",
        "1d) Answer the **key question below** in your copy of this notebook by typing your answer below the question in this text cell.\n",
        "\n",
        "Compare results with team members, and discuss as a group. Ask for help if needed.\n",
        "\n",
        "#### **Thinking About The Data Question, Task 1**: In this notebook, one-dimensional arrays are used for data entry and calculations.  Use your prior knowledge of arrays, the information above, and the sample-code below to answer the following:\n",
        "* Q1a. Was it easy or hard to figure out where to enter different types of data into the sample-code?  Explain briefly.\n",
        "* Q1b. For chromatograms with more than one peak, the sample-code expects array data to be entered in order of increasing retention time.  For replicate vials, the sample-code expects array data to be entered in the same order each time.  What do you think would happen if the data were entered in a different order? Explain briefly.\n",
        "\n",
        "---\n",
        "```python\n",
        "#### The code below is for:\n",
        "import numpy as np\n",
        "\n",
        "#### The code below is for:\n",
        "Caffeine_Stock_Concentration_From_Bottle_in_ug_per_mL =\n",
        "#### The code below is for:\n",
        "Aspirin_Stock_Concentration_From_Bottle_in_ug_per_mL =\n",
        "#### The code below is for:\n",
        "Tylenol_Stock_Concentration_From_Bottle_in_ug_per_mL =\n",
        "\n",
        "#### The code below is for:\n",
        "Standard_Stock_Volumes_in_uL = np.array([50, 100, 500, 1000])\n",
        "#### The code below is for:\n",
        "Standard_Solvent_Volumes_in_uL = np.array([950, 900, 500, 0])\n",
        "\n",
        "#### The code below is for:\n",
        "Standard_Total_Volumes_in_uL = Standard_Stock_Volumes_in_uL + Standard_Solvent_Volumes_in_uL\n",
        "#### The code below is for:\n",
        "Standard_Dilution_Factors = Standard_Total_Volumes_in_uL/Standard_Stock_Volumes_in_uL\n",
        "\n",
        "#### The code below is for:\n",
        "Caffeine_Standard_Concentrations_in_ug_per_mL = Caffeine_Stock_Concentration_From_Bottle_in_ug_per_mL/Standard_Dilution_Factors\n",
        "#### The code below is for:\n",
        "Aspirin_Standard_Concentrations_in_ug_per_mL = Aspirin_Stock_Concentration_From_Bottle_in_ug_per_mL/Standard_Dilution_Factors\n",
        "#### The code below is for:\n",
        "Tylenol_Standard_Concentrations_in_ug_per_mL = Tylenol_Stock_Concentration_From_Bottle_in_ug_per_mL/Standard_Dilution_Factors\n",
        "\n",
        "#### The code below is for:\n",
        "Sample_Initial_Volume_in_mL = 100\n",
        "#### The code below is for:\n",
        "Spiked_Vial_Sample_Volume_in_uL = 50\n",
        "#### The code below is for:\n",
        "Spiked_Vial_Stock_Volume_in_uL = 500\n",
        "#### The code below is for:\n",
        "Spiked_Vial_Solvent_Volume_in_uL = 450\n",
        "\n",
        "#### The code below is for:\n",
        "Spiked_Vial_Total_Volume_in_uL = Spiked_Vial_Sample_Volume_in_uL + Spiked_Vial_Stock_Volume_in_uL + Spiked_Vial_Solvent_Volume_in_uL\n",
        "#### The code below is for:\n",
        "Spiked_Vial_Sample_Dilution_Factor = Spiked_Vial_Total_Volume_in_uL/Spiked_Vial_Sample_Volume_in_uL\n",
        "#### The code below is for:\n",
        "Spiked_Vial_Stock_Dilution_Factor = Spiked_Vial_Total_Volume_in_uL/Spiked_Vial_Stock_Volume_in_uL\n",
        "#### The code below is for:\n",
        "\n",
        "Caffeine_Spiked_Vial_Stock_Concentration =  Caffeine_Stock_Concentration_From_Bottle_in_ug_per_mL/Spiked_Vial_Stock_Dilution_Factor\n",
        "#### The code below is for:\n",
        "Aspirin_Spiked_Vial_Stock_Concentration =  Aspirin_Stock_Concentration_From_Bottle_in_ug_per_mL/Spiked_Vial_Stock_Dilution_Factor\n",
        "#### The code below is for:\n",
        "Tylenol_Spiked_Vial_Stock_Concentration =  Tylenol_Stock_Concentration_From_Bottle_in_ug_per_mL/Spiked_Vial_Stock_Dilution_Factor\n",
        "\n",
        "#### The code below is for:\n",
        "Sample_Vial_Sample_Volume_in_uL = 100\n",
        "#### The code below is for:\n",
        "Sample_Vial_Solvent_Volume_in_uL = 900\n",
        "\n",
        "#### The code below is for:\n",
        "Sample_Vial_Total_Volume_in_uL = Sample_Vial_Sample_Volume_in_uL + Sample_Vial_Solvent_Volume_in_uL\n",
        "#### The code below is for:\n",
        "Sample_Vial_Dilution_Factor = Sample_Vial_Total_Volume_in_uL/Sample_Vial_Sample_Volume_in_uL\n",
        "\n",
        "#### The code below is for:\n",
        "Caffeine_Standard_Peak_Areas = np.array([ , , , ])\n",
        "#### The code below is for:\n",
        "Aspirin_Standard_Peak_Areas = np.array([ , , , ])\n",
        "#### The code below is for:\n",
        "Tylenol_Standard_Peak_Areas = np.array([ , , , ])\n",
        "\n",
        "#### The code below is for:\n",
        "Caffeine_Spiked_Vial_Retention_Times = np.array([ , , ])\n",
        "#### The code below is for:\n",
        "Caffeine_Spiked_Vial_Peak_Areas = np.array([ , , ])\n",
        "#### The code below is for:\n",
        "Aspirin_Spiked_Vial_Retention_Times = np.array([ , , ])\n",
        "#### The code below is for:\n",
        "Aspirin_Spiked_Vial_Peak_Areas = np.array([, , ])\n",
        "#### The code below is for:\n",
        "Tylenol_Spiked_Vial_Retention_Times = np.array([, , ])\n",
        "#### The code below is for:\n",
        "Tylenol_Spiked_Vial_Peak_Areas = np.array([, , ])\n",
        "\n",
        "#### The code below is for:\n",
        "Replicate_Sample_Vial_Retention_Times = np.array([[, , ],[, , ],[, , ]])\n",
        "#### The code below is for:\n",
        "Replicate_Sample_Vial_Peak_Areas = np.array([[, , ],[, , ],[, , ]])\n",
        "\n",
        "#### The code below is for:\n",
        "print(f\"Caffeine Standard Concentrations in mg/mL and Peak Areas\")\n",
        "for vial in range(4):\n",
        "    print(f\"{Caffeine_Standard_Concentrations_in_ug_per_mL[vial]:.1f}, {Caffeine_Standard_Peak_Areas[vial]:.1f}\")\n",
        "#### The code below is for:\n",
        "print(f\"Aspirin Standard Concentrations in mg/mL and Peak Areas\")\n",
        "for vial in range(4):\n",
        "    print(f\"{Aspirin_Standard_Concentrations_in_ug_per_mL[vial]:.1f}, {Aspirin_Standard_Peak_Areas[vial]:.1f}\")\n",
        "#### The code below is for:\n",
        "print(f\"Tylenol Standard Concentrations in mg/mL and Peak Areas\")\n",
        "for vial in range(4):\n",
        "    print(f\"{Tylenol_Standard_Concentrations_in_ug_per_mL[vial]:.1f}, {Tylenol_Standard_Peak_Areas[vial]:.1f}\")\n",
        "```\n",
        "---"
      ],
      "metadata": {
        "id": "iGcLtNJRUPnh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qynL0VZ4MZPY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: Find the best-fit parameters and standard uncertainties to relate each analyte's peak area to its concentration; and generate calibration curves using data arrays and best-fit model arrays\n",
        "\n",
        "In this task, we will use linregress, a function in the statistics module of the SciPy package.  The fitting routine in SciPy includes uncertainties along with best-fit parameters.  We also will use Matplotlib to plot data and a best-fit model, along with error bars to represent uncertainty in the model.\n",
        "\n",
        "Using the information above:\n",
        "\n",
        "2a)  Double-click here in this **text cell** and type into each of the comment lines to **explain the purpose** of each line of sample-code below in this text cell(they should look like the example shown here).\n",
        "\n",
        "---\n",
        "```\n",
        "#### The code below is for:\n",
        "```\n",
        "---\n",
        "\n",
        "2b)  Copy/paste all the code along with your explanations into the **code cell** just below this text cell, and run it.  \n",
        "\n",
        "2c)  Answer the **key question below** in your copy of this notebook by typing your answer below the question in this text cell.\n",
        "\n",
        "Compare results with team members, and discuss as a group.  Ask for help if needed.\n",
        "\n",
        "#### **Thinking About The Data Question, Task 2**:\n",
        "\n",
        "* Q2a.  How well does the linear regression model fit your data?  Discuss as a team and decide whether all data points fit *exactly* to the model.  Also decide whether all data points fit to the model *within* standard error bars.  Explain briefly.\n",
        "* Q2b.  Standard error from the linear model will not be the only source of uncertainty in this analysis.  In Task 4, we will find analyte concentrations over several trials, and calculate the corresponding standard deviations. What source of uncertainty is represented by those standard deviations?\n",
        "\n",
        "---\n",
        "```python\n",
        "#### The code below is for:\n",
        "import scipy\n",
        "from scipy.stats import linregress\n",
        "#### The code below is for:\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#### The code below is for:\n",
        "Caffeine_linear_best_fit = linregress(Caffeine_Standard_Concentrations_in_ug_per_mL,Caffeine_Standard_Peak_Areas)\n",
        "#### The code below is for:\n",
        "Aspirin_linear_best_fit = linregress(Aspirin_Standard_Concentrations_in_ug_per_mL,Aspirin_Standard_Peak_Areas)\n",
        "#### The code below is for:\n",
        "Tylenol_linear_best_fit = linregress(Tylenol_Standard_Concentrations_in_ug_per_mL,Tylenol_Standard_Peak_Areas)\n",
        "####The code below is for:\n",
        "print(\"Caffeine Model: \",Caffeine_linear_best_fit,\"\\n\")\n",
        "print(\"Aspirin Model: \",Aspirin_linear_best_fit,\"\\n\")\n",
        "print(\"Tylenol Model: \",Tylenol_linear_best_fit,\"\\n\")\n",
        "\n",
        "#### The code below is for:\n",
        "three_part_figure = plt.figure(figsize=(16,4))\n",
        "#### The code below is for:\n",
        "plot_c, plot_a, plot_t = three_part_figure.subplots(1,3,sharex=False,sharey=False)\n",
        "#### The code below is for:\n",
        "plot_c.set_title('Caffeine Calibration Curve')\n",
        "plot_a.set_title('Aspirin Calibration Curve')\n",
        "plot_t.set_title('Tylenol Calibration Curve')\n",
        "#### The code below is for:\n",
        "plot_c.set_xlabel('Stock Concentration in ug/mL')\n",
        "plot_a.set_xlabel('Stock Concentration in ug/mL')\n",
        "plot_t.set_xlabel('Stock Concentration in ug/mL')\n",
        "plot_c.set_ylabel('Caffeine Peak Area in mAu*s')\n",
        "plot_a.set_ylabel('Aspirin Peak Area in mAu*s')\n",
        "plot_t.set_ylabel('Tylenol Peak Area in mAu*s')\n",
        "\n",
        "#### The code below is for:\n",
        "label_c = \"Caffeine model with error bars:\\n y = ({slope:.2f}±{m_stderr:.2f})x + ({intercept:.2f}±{b_stderr:.2f})\".format(slope=Caffeine_linear_best_fit.slope,intercept=Caffeine_linear_best_fit.intercept,m_stderr=Caffeine_linear_best_fit.stderr,b_stderr=Caffeine_linear_best_fit.intercept_stderr)\n",
        "label_a = \"Aspirin model with error bars:\\n y = ({slope:.2f}±{m_stderr:.2f})x + ({intercept:.2f}±{b_stderr:.2f})\".format(slope=Aspirin_linear_best_fit.slope,intercept=Aspirin_linear_best_fit.intercept,m_stderr=Aspirin_linear_best_fit.stderr,b_stderr=Aspirin_linear_best_fit.intercept_stderr)\n",
        "label_t = \"Tylenol model with error bars:\\n y = ({slope:.2f}±{m_stderr:.2f})x + ({intercept:.2f}±{b_stderr:.2f})\".format(slope=Tylenol_linear_best_fit.slope,intercept=Tylenol_linear_best_fit.intercept,m_stderr=Tylenol_linear_best_fit.stderr,b_stderr=Tylenol_linear_best_fit.intercept_stderr)\n",
        "\n",
        "#### The code below is for:\n",
        "Caffeine_model = Caffeine_Standard_Concentrations_in_ug_per_mL*Caffeine_linear_best_fit.slope + Caffeine_linear_best_fit.intercept\n",
        "Aspirin_model = Aspirin_Standard_Concentrations_in_ug_per_mL*Aspirin_linear_best_fit.slope + Aspirin_linear_best_fit.intercept\n",
        "Tylenol_model = Tylenol_Standard_Concentrations_in_ug_per_mL*Tylenol_linear_best_fit.slope + Tylenol_linear_best_fit.intercept\n",
        "#### The code below is for:\n",
        "#### (Note: This code was debugged 4/1/25)\n",
        "Caffeine_model_yerr = np.sqrt(np.sum((Caffeine_Standard_Peak_Areas-Caffeine_model)**2)/(len(Caffeine_model)-2))\n",
        "Aspirin_model_yerr = np.sqrt(np.sum((Aspirin_Standard_Peak_Areas-Aspirin_model)**2)/(len(Aspirin_model)-2))\n",
        "Tylenol_model_yerr = np.sqrt(np.sum((Tylenol_Standard_Peak_Areas-Tylenol_model)**2)/(len(Tylenol_model)-2))\n",
        "\n",
        "#### The code below is for:\n",
        "plot_c.plot(Caffeine_Standard_Concentrations_in_ug_per_mL,Caffeine_Standard_Peak_Areas,'ob')\n",
        "plot_a.plot(Aspirin_Standard_Concentrations_in_ug_per_mL,Aspirin_Standard_Peak_Areas,'oc')\n",
        "plot_t.plot(Tylenol_Standard_Concentrations_in_ug_per_mL,Tylenol_Standard_Peak_Areas,'og')\n",
        "#### The code below is for:\n",
        "plot_c.errorbar(Caffeine_Standard_Concentrations_in_ug_per_mL,Caffeine_model,yerr=Caffeine_model_yerr,fmt='--b', capsize=5, label=label_c)\n",
        "plot_a.errorbar(Aspirin_Standard_Concentrations_in_ug_per_mL,Aspirin_model,yerr=Aspirin_model_yerr,fmt='--c', capsize=5, label=label_a)\n",
        "plot_t.errorbar(Tylenol_Standard_Concentrations_in_ug_per_mL,Tylenol_model,yerr=Tylenol_model_yerr,fmt='--g', capsize=5, label=label_t)\n",
        "\n",
        "#### The code below is for:\n",
        "plot_c.legend()\n",
        "plot_a.legend()\n",
        "plot_t.legend()\n",
        "#### The code below is for:\n",
        "three_part_figure.show()\n",
        "```\n",
        "---"
      ],
      "metadata": {
        "id": "JyEP7FpSqD6I"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GnPqfzjZtels"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3: Use measured retention times and peak areas of spiked samples to identify analyte peaks in a chromatogram of a mixture, and to estimate each analyte's concentration in the mixture\n",
        "\n",
        "In this task, we will define a Python function to identify analyte peaks.  However, you should look at your spiked chromatograms and verify that you agree with the automated peak assignment.  We also will define a Python function to estimate each analyte's concentration in the mixture.  However, you should verify this rough estimate with the quantitative analysis to be completed in Task 4.\n",
        "\n",
        "Using the information above:\n",
        "\n",
        "3a)  Double-click here in this **text cell** and type into each of the comment lines to **explain the purpose** of each line of sample-code below in this text cell(they should look like the example shown here).\n",
        "\n",
        "---\n",
        "```\n",
        "#### The code below is for:\n",
        "```\n",
        "---\n",
        "\n",
        "3b)  Copy/paste all the code along with your explanations into the **code cell** just below this text cell, and run it.  \n",
        "\n",
        "3c)  Answer the **key question below** in your copy of this notebook by typing your answer below the question in this text cell.\n",
        "\n",
        "Compare results with team members, and discuss as a group.  Ask for help if needed.\n",
        "\n",
        "#### **Thinking About The Data Question, Task 3**: This task generates peak assignments and estimates analyte concentrations.  Use your chromatograms and your output from this task to answer the following:\n",
        "* Q3a. Based on your chromatograms of spiked samples, do you agree with all three automated peak assignments? Explain briefly.\n",
        "* Q3b. Based on your chromatograms of spiked samples and the reported spike concentrations for each analyte, do you agree with all three automated estimates of analyte concentrations?  Explain briefly.\n",
        "* Q3c. (Challenge) Suppose your chromatogram peaks were not well-separated.  Which measurement would that affect more: retention times, or peak areas?  Explain briefly.\n",
        "* Q3d. (Challenge) Suppose your chromatogram peaks were asymmetric.  Which measurement would that affect more: retention times, or peak areas?  Explain briefly.\n",
        "\n",
        "---\n",
        "```python\n",
        "#### The code below is for:\n",
        "def peak_assign(spiked_average_areas, spiked_areas_array):\n",
        "    n_spikes = len(spiked_areas_array)\n",
        "    for peak in range(n_spikes):\n",
        "        if spiked_areas_array[peak] > spiked_average_areas[peak]:\n",
        "            assignment = peak\n",
        "    return assignment  \n",
        "\n",
        "#### The code below is for:\n",
        "Spiked_average_retention_times = np.average(np.array([Caffeine_Spiked_Vial_Retention_Times,Aspirin_Spiked_Vial_Retention_Times,Tylenol_Spiked_Vial_Retention_Times]), axis=0)\n",
        "#### The code below is for:\n",
        "Spiked_average_peak_areas = np.average(np.array([Caffeine_Spiked_Vial_Peak_Areas,Aspirin_Spiked_Vial_Peak_Areas,Tylenol_Spiked_Vial_Peak_Areas]), axis=0)\n",
        "\n",
        "#### The code below is for:\n",
        "Caffeine_peak = peak_assign(Spiked_average_peak_areas, Caffeine_Spiked_Vial_Peak_Areas)\n",
        "Aspirin_peak = peak_assign(Spiked_average_peak_areas, Aspirin_Spiked_Vial_Peak_Areas)\n",
        "Tylenol_peak = peak_assign(Spiked_average_peak_areas, Tylenol_Spiked_Vial_Peak_Areas)\n",
        "\n",
        "#### The code below is for:\n",
        "Caffeine_peak_sample = np.average([Aspirin_Spiked_Vial_Peak_Areas[Caffeine_peak], Tylenol_Spiked_Vial_Peak_Areas[Caffeine_peak]])\n",
        "Aspirin_peak_sample = np.average([Caffeine_Spiked_Vial_Peak_Areas[Aspirin_peak], Tylenol_Spiked_Vial_Peak_Areas[Aspirin_peak]])\n",
        "Tylenol_peak_sample = np.average([Caffeine_Spiked_Vial_Peak_Areas[Tylenol_peak], Aspirin_Spiked_Vial_Peak_Areas[Tylenol_peak]])\n",
        "#### The code below is for:\n",
        "Caffeine_concentration_mg_per_mL = ((Caffeine_peak_sample-Caffeine_linear_best_fit.intercept)/Caffeine_linear_best_fit.slope)*Spiked_Vial_Sample_Dilution_Factor/1000\n",
        "Aspirin_concentration_mg_per_mL = ((Aspirin_peak_sample-Aspirin_linear_best_fit.intercept)/Aspirin_linear_best_fit.slope)*Spiked_Vial_Sample_Dilution_Factor/1000\n",
        "Tylenol_concentration_mg_per_mL = ((Tylenol_peak_sample-Tylenol_linear_best_fit.intercept)/Tylenol_linear_best_fit.slope)*Spiked_Vial_Sample_Dilution_Factor/1000\n",
        "\n",
        "#### The code below is for:\n",
        "print(f\"Caffeine peak average retention time: {Spiked_average_retention_times[Caffeine_peak]:.2f} min; approximate concentration: {Caffeine_concentration_mg_per_mL:.2f} mg/mL\")\n",
        "print(f\"Aspirin  peak average retention time: {Spiked_average_retention_times[Aspirin_peak]:.2f} min; approximate concentration: {Aspirin_concentration_mg_per_mL:.2f} mg/mL\")\n",
        "print(f\"Tylenol  peak average retention time: {Spiked_average_retention_times[Tylenol_peak]:.2f} min; approximate concentration: {Tylenol_concentration_mg_per_mL:.2f} mg/mL\")\n",
        "```\n",
        "---"
      ],
      "metadata": {
        "id": "Y9VVn-Gx8UmO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jgnRD5xkABrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4: Calculate each unknown analyte's concentration and standard uncertainty; use these concentrations to calculate total amounts per tablet in mg.\n",
        "\n",
        "In this task, we will calculate analyte concentrations more accurately, using the data from replicate sample vials.  We also will calculate the uncertainty in analyte concentrations; this is not done automatically by the linregress function, so we will define a function (as shown below) to calculate standard uncertainty.  Finally, we will use the analyte concentrations to determine the total analyte content in the original sample.\n",
        "\n",
        "When applying a linear regression model to calculate an unknown concentration, the standard uncertainty in the calculated value $x$ is given by the following equation:\n",
        "\n",
        "$ s_x= \\frac{s_y}{|m|} \\sqrt{\\frac{1}{k} + \\frac{1}{n} + \\frac{(y-\\bar{y})^2}{m^2 \\sum(x_i-\\bar{x})^2}}$\n",
        "\n",
        "where $s_y = \\sqrt{\\frac{\\sum(y-y_{model})^2}{n-2}}$ is the \"model_yerr\" you calculated in Task 3 to plot the model with y-error bars; $m$ is the absolute value of the slope; $k$ is the number of replicate measurements (in this case, k = 1); $n$ is the number of data points used to fit the model; $y$ is the measured value; and $\\bar{x}$ and $\\bar{y}$ are the average $x$-value and $y$-value of data points used to fit the model.\n",
        "\n",
        "Using the information above:\n",
        "\n",
        "4a)  Double-click here in this **text cell** and type into each of the comment lines to **explain the purpose** of each line of sample-code below in this text cell(they should look like the example shown here).\n",
        "\n",
        "---\n",
        "```\n",
        "#### The code below is for:\n",
        "```\n",
        "---\n",
        "\n",
        "4b)  Copy/paste all the code along with your explanations into the **code cell** just below this text cell, and run it.  \n",
        "\n",
        "4c)  Answer the **key question below** in your copy of this notebook by typing your answer below the question in this text cell.\n",
        "\n",
        "Compare results with team members, and discuss as a group.  Ask for help if needed.\n",
        "\n",
        "#### **Thinking About The Data Question, Task 4**: This task quantitatively calculates analyte concentrations with their uncertainty, and uses these to determine the total analyte content in the original sample.  Use your chromatograms; your prior knowledge of *calibration curves* and *general chemistry*, your output from Task 3, and your output from this task to answer the following:\n",
        "* Q4a. Where did the uncertainty come from?  List at least two sources.\n",
        "* Q4b. Why was it necessary to use a calibration curve and replicate trials to accurately calculate the analyte concentrations?  What sources of error does each of these practices seek to mitigate?  Explain briefly.\n",
        "* Q4c. How good were the estimates from Task 3? Did they *each* fall within the range of concentrations determined for each analyte in Task 4?  If not, are they higher or lower, and by how much?  Compare the values, and explain briefly.\n",
        "* Q4d. How good were the (outdated) labeled analyte concentrations on your sample?  Did they *each* fall within the range of concentrations determined for each analyte in Task 4?  If not, are they higher or lower, and by how much?  Compare the values, and explain briefly.\n",
        "* Q4e. Suppose your chromatogram peaks were asymmetric, or were not well-separated.  Would that affect the measured values enough to account for any discrepancies you may have noted above?  Explain briefly.\n",
        "* Q5e.  Are there any small peaks in your chromatograms that we have not analyzed?  What do you think those might be?  Thinking of chemical reactions that could happen over time with your sample, could these help to account for any discrepancies between the (outdated) label and your analysis?  Explain briefly.\n",
        "\n",
        "---\n",
        "```python\n",
        "#### The code below is for:\n",
        "def standard_uncertainty(y,k,n,m,s_y,x_data,y_data):\n",
        "    x_average = np.average(x_data)\n",
        "    y_average = np.average(y_data)\n",
        "    s_xx = np.sum((x_data-x_average)**2)\n",
        "    s_x = (s_y/abs(m))*np.sqrt((1/k)+(1/n)+(((y-y_average)**2)/((m*m*s_xx))))\n",
        "    return s_x\n",
        "\n",
        "#### The code below is for:\n",
        "Replicate_average_retention_times = np.average(Replicate_Sample_Vial_Retention_Times, axis=0)\n",
        "#### The code below is for:\n",
        "Replicate_average_peak_areas = np.average(Replicate_Sample_Vial_Peak_Areas, axis=0)\n",
        "\n",
        "#### The code below is for:\n",
        "k_replicates = np.shape(Replicate_Sample_Vial_Peak_Areas)[1]\n",
        "\n",
        "#### The code below is for:\n",
        "Caffeine_avg_conc_ug_per_mL = ((Replicate_average_peak_areas[Caffeine_peak]-Caffeine_linear_best_fit.intercept)/Caffeine_linear_best_fit.slope)\n",
        "Aspirin_avg_conc_ug_per_mL = ((Replicate_average_peak_areas[Aspirin_peak]-Aspirin_linear_best_fit.intercept)/Aspirin_linear_best_fit.slope)\n",
        "Tylenol_avg_conc_ug_per_mL = ((Replicate_average_peak_areas[Tylenol_peak]-Tylenol_linear_best_fit.intercept)/Tylenol_linear_best_fit.slope)\n",
        "\n",
        "#### The code below is for:\n",
        "Caffeine_avg_conc_propagated_uncertainty = standard_uncertainty(Caffeine_avg_conc_ug_per_mL,k_replicates,len(Caffeine_Standard_Peak_Areas),Caffeine_linear_best_fit.slope,Caffeine_model_yerr,Caffeine_Standard_Concentrations_in_ug_per_mL,Caffeine_Standard_Peak_Areas)\n",
        "Aspirin_avg_conc_propagated_uncertainty = standard_uncertainty(Aspirin_avg_conc_ug_per_mL,k_replicates,len(Aspirin_Standard_Peak_Areas),Aspirin_linear_best_fit.slope,Aspirin_model_yerr,Aspirin_Standard_Concentrations_in_ug_per_mL,Aspirin_Standard_Peak_Areas)\n",
        "Tylenol_avg_conc_propagated_uncertainty = standard_uncertainty(Tylenol_avg_conc_ug_per_mL,k_replicates,len(Tylenol_Standard_Peak_Areas),Tylenol_linear_best_fit.slope,Tylenol_model_yerr,Tylenol_Standard_Concentrations_in_ug_per_mL,Tylenol_Standard_Peak_Areas)\n",
        "\n",
        "#### The code below is for:\n",
        "Caffeine_avg_conc_mg_per_mL = Caffeine_avg_conc_ug_per_mL*Sample_Vial_Dilution_Factor/1000\n",
        "Aspirin_avg_conc_mg_per_mL = Aspirin_avg_conc_ug_per_mL*Sample_Vial_Dilution_Factor/1000\n",
        "Tylenol_avg_conc_mg_per_mL = Tylenol_avg_conc_ug_per_mL*Sample_Vial_Dilution_Factor/1000\n",
        "\n",
        "#### The code below is for:\n",
        "Caffeine_avg_conc_propagated_uncertainty = Caffeine_avg_conc_propagated_uncertainty*Sample_Vial_Dilution_Factor/1000\n",
        "Aspirin_avg_conc_propagated_uncertainty = Aspirin_avg_conc_propagated_uncertainty*Sample_Vial_Dilution_Factor/1000\n",
        "Tylenol_avg_conc_propagated_uncertainty =\n",
        "Tylenol_avg_conc_propagated_uncertainty*Sample_Vial_Dilution_Factor/1000\n",
        "\n",
        "#### The code below is for:\n",
        "print(f\"Caffeine peak average retention time: {Replicate_average_retention_times[Caffeine_peak]:.2f} min; concentration: {Caffeine_avg_conc_mg_per_mL:.2f} mg/mL; standard uncertainty: {Caffeine_avg_conc_propagated_uncertainty:.2f} mg/mL\")\n",
        "print(f\"Aspirin  peak average retention time: {Replicate_average_retention_times[Aspirin_peak]:.2f} min; concentration: {Aspirin_avg_conc_mg_per_mL:.2f} mg/mL; standard uncertainty: {Aspirin_avg_conc_propagated_uncertainty:.2f} mg/mL\")\n",
        "print(f\"Tylenol  peak average retention time: {Replicate_average_retention_times[Tylenol_peak]:.2f} min; concentration: {Tylenol_avg_conc_mg_per_mL:.2f} mg/mL; standard uncertainty: {Tylenol_avg_conc_propagated_uncertainty:.2f} mg/mL\")\n",
        "#### The code below is for:\n",
        "print(f\"Excedrin tablet analysis results: {Caffeine_avg_conc_mg_per_mL*Sample_Initial_Volume_in_mL:.1f} ± {Caffeine_avg_conc_propagated_uncertainty*Sample_Initial_Volume_in_mL:.1f} mg caffeine; {Aspirin_avg_conc_mg_per_mL*Sample_Initial_Volume_in_mL:.0f} ± {Aspirin_avg_conc_propagated_uncertainty*Sample_Initial_Volume_in_mL:.0f} mg aspirin; {Tylenol_avg_conc_mg_per_mL*Sample_Initial_Volume_in_mL:.0f} ± {Tylenol_avg_conc_propagated_uncertainty*Sample_Initial_Volume_in_mL:.0f} mg tylenol\")\n",
        "print(f\"These results are for the mass of tablet originally dissolved, as recorded in your laboratory notebook.\")\n",
        "```\n",
        "---"
      ],
      "metadata": {
        "id": "NRuoF2QEt-1f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lCM9tjgOupBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Congratulations, you did it!***  \n",
        "Please download your copy of this notebook to turn in.\n",
        "\n",
        "Remember to write a summary in your laboratory notebook, by hand, and to turn in copies of your notebook pages."
      ],
      "metadata": {
        "id": "ZjD38lQZa7ee"
      }
    }
  ]
}